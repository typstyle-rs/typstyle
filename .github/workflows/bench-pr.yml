name: Benchmark for PR
# This workflow runs benchmarks in parallel jobs with caching for performance.
# Base benchmarks use the upstream repository to ensure base revision exists.
# PR benchmarks use the fork repository for the head revision.
# Results are compared in a final job using artifacts for reliable data transfer.

permissions:
  contents: read
  actions: read
  pull-requests: read

on:
  pull_request:
    paths:
      - "crates/typstyle-core/**"
      - ".github/workflows/bench-pr.yml"
  workflow_dispatch:
    inputs:
      force_rerun:
        description: "Force re-run benchmarks even if cache exists"
        required: false
        default: false
        type: boolean

jobs:
  pre_job:
    permissions:
      actions: write
      contents: read
    name: Duplicate Actions Detection
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@v5
        with:
          cancel_others: "true"

  bench-base:
    name: Benchmark base branch
    uses: ./.github/workflows/bench-job.yml
    needs: pre_job
    if: needs.pre_job.outputs.should_skip != 'true'
    with:
      branch_type: base
      git_ref: ${{ github.event.pull_request.base.sha }}
      repository: ${{ github.event.pull_request.base.repo.full_name }}
      force_rerun: ${{ github.event.inputs.force_rerun || false }}

  bench-pr:
    name: Benchmark PR branch
    uses: ./.github/workflows/bench-job.yml
    needs: pre_job
    if: needs.pre_job.outputs.should_skip != 'true'
    with:
      branch_type: pr
      git_ref: ${{ github.event.pull_request.head.ref }}
      repository: ${{ github.event.pull_request.head.repo.full_name }}
      force_rerun: ${{ github.event.inputs.force_rerun || false }}

  compare:
    name: Generate benchmark comparison
    runs-on: ubuntu-latest
    needs: [bench-base, bench-pr]
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y bc

      - name: Install critcmp
        uses: taiki-e/install-action@v2
        with:
          tool: critcmp

      - name: Download base benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-base
          path: base-results

      - name: Download PR benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-pr
          path: pr-results

      - name: Prepare benchmark data for comparison
        run: |
          mkdir -p target/criterion

          # Merge base and PR benchmark results
          cp -r base-results/* target/criterion/ 2>/dev/null || true
          cp -r pr-results/* target/criterion/ 2>/dev/null || true

          echo "Final benchmark structure:"
          ls -la target/criterion/

      - name: Generate comparison results
        run: |
          # Generate benchmark comparison
          BENCH_RESULT=$(critcmp --color never base pr)

          # Generate binary size comparison
          BINARY_SIZE_REPORT=""
          if [ -f "base-results/bloat/size-base.bytes" ] && [ -f "pr-results/bloat/size-pr.bytes" ]; then
            BASE_SIZE=$(cat base-results/bloat/size-base.bytes)
            PR_SIZE=$(cat pr-results/bloat/size-pr.bytes)
            DIFF=$((PR_SIZE - BASE_SIZE))

            # Convert to human readable format
            BASE_SIZE_HUMAN=$(numfmt --to=iec-i --suffix=B $BASE_SIZE)
            PR_SIZE_HUMAN=$(numfmt --to=iec-i --suffix=B $PR_SIZE)

            # Calculate change indicators
            if [ $DIFF -eq 0 ]; then
              DIFF_TEXT="no change"
              EMOJI="="
            elif [ $DIFF -gt 0 ]; then
              DIFF_HUMAN=$(numfmt --to=iec-i --suffix=B $DIFF)
              DIFF_PERCENT=$(echo "scale=2; $DIFF * 100.0 / $BASE_SIZE" | bc -l)
              DIFF_TEXT="+$DIFF_HUMAN (+${DIFF_PERCENT}%)"
              EMOJI="ðŸ“ˆ"
            else
              DIFF_ABS=$((-DIFF))
              DIFF_HUMAN=$(numfmt --to=iec-i --suffix=B $DIFF_ABS)
              DIFF_PERCENT=$(echo "scale=2; $DIFF_ABS * 100.0 / $BASE_SIZE" | bc -l)
              DIFF_TEXT="-$DIFF_HUMAN (-${DIFF_PERCENT}%)"
              EMOJI="ðŸ“‰"
            fi

            # Generate crate-level diff if bloat data available
            BLOAT_DETAILS=""
            if [ -f "base-results/bloat/bloat-base.json" ] && [ -f "pr-results/bloat/bloat-pr.json" ] && command -v jq > /dev/null; then
              # Extract top 10 crates with sizes from both branches
              BASE_CRATES=$(jq -r '.crates[:10] | map("| \(.name) | \(.size) |") | .[]' base-results/bloat/bloat-base.json 2>/dev/null)
              PR_CRATES=$(jq -r '.crates[:10] | map("| \(.name) | \(.size) |") | .[]' pr-results/bloat/bloat-pr.json 2>/dev/null)

              if [ -n "$BASE_CRATES" ] && [ -n "$PR_CRATES" ]; then
                echo "$BASE_CRATES" > base_crates.tmp
                echo "$PR_CRATES" > pr_crates.tmp

                DIFF_OUTPUT=$(diff -u base_crates.tmp pr_crates.tmp | tail -n +3 || true)
                if [ -n "$DIFF_OUTPUT" ]; then
                  BLOAT_DETAILS="

          <details>
          <summary>ðŸ“¦ Detailed Crate Size Diff (cargo-bloat)</summary>

          Note: numbers above are a result of guesswork. They are not 100% correct and never will be.

          \`\`\`diff
          $DIFF_OUTPUT
          \`\`\`

          </details>"
                fi
                rm -f base_crates.tmp pr_crates.tmp
              fi
            fi

            BINARY_SIZE_REPORT="

          ### ðŸ“ Binary Size Comparison

          | Branch | Size | Change |
          |--------|------|--------|
          | Base   | $BASE_SIZE_HUMAN | - |
          | PR     | $PR_SIZE_HUMAN | $EMOJI $DIFF_TEXT |$BLOAT_DETAILS"
          else
            BINARY_SIZE_REPORT="

          ### ðŸ“ Binary Size Comparison

          âš ï¸ Binary size data not available for comparison."
          fi

          # Save results to file for the comment workflow
          cat > benchmark-results.md << EOF
          ### ðŸ“Š Benchmark Performance Report

          \`\`\`console
          $BENCH_RESULT
          \`\`\`

          $BINARY_SIZE_REPORT

          Generated by GitHub Actions on $(date)
          EOF

          echo "Generated benchmark comparison report"
          cat benchmark-results.md

      - name: Save PR number
        run: |
          mkdir -p ./pr-info
          echo ${{ github.event.pull_request.number }} > ./pr-info/PR_NUMBER
          echo "Saved PR number: ${{ github.event.pull_request.number }}"

      - name: Upload benchmark comparison and PR info
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-comparison
          path: |
            benchmark-results.md
            pr-info/
          retention-days: 7
